{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a6492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## downloading corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420344c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:53:33.757620: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 12:53:34.279851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-01 12:53:34.279882: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-01 12:53:34.368095: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 12:53:35.521927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-01 12:53:35.522079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-01 12:53:35.522088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384b592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b6dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length :  600893\n"
     ]
    }
   ],
   "source": [
    "text = open(path).read().lower()\n",
    "print('Corpus length : ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91b9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorization of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dfbe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "step = 6\n",
    "sentences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991a41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_char.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c0ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fce74768",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5998814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(shape = (len(sentences), maxlen, len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecee4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(shape = (len(next_char), len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "040fef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for j, ch in enumerate(chars):\n",
    "        x[i, j, char_indices[ch]] = 1\n",
    "    y[i, char_indices[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5a4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e2a5052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:53:39.529559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-07-01 12:53:39.529905: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-01 12:53:39.529936: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mukesh-ThinkPad-E14): /proc/driver/nvidia/version does not exist\n",
      "2024-07-01 12:53:39.530672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape = (maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f9767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               95232     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 57)                7353      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4527b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.RMSprop(learning_rate = 0.001),\n",
    "    loss = 'categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df2a4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e081ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probs = np.randoom.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9ed7432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:53:41.100028: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1369901520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 71s 88ms/step - loss: 3.0368\n",
      "-------------- Generated Text Seed------------------\n",
      "ey follow\n",
      "one another with lightning rapidity are no longer \n",
      "----------------- temperature -------------0.2\n",
      "ey follow\n",
      "one another with lightning rapidity are no longer [1.83370076e-02 1.22712776e-01 8.57344188e-04 2.76150228e-03\n",
      " 5.43052971e-04 3.15491052e-04 4.07504966e-04 1.64989009e-02\n",
      " 6.43500779e-03 6.10851916e-03 4.19005737e-05 5.86373906e-04\n",
      " 5.18426474e-04 1.20660952e-04 4.92285071e-05 1.03191815e-05\n",
      " 4.96331413e-05 2.56419662e-05 2.28384524e-05 7.09000369e-06\n",
      " 1.05001591e-03 1.00798393e-03 3.52105446e-04 5.51353674e-04\n",
      " 2.08067886e-05 1.03721635e-04 2.37273835e-05 5.57050593e-02\n",
      " 1.11897970e-02 2.35532243e-02 2.97662821e-02 9.37712789e-02\n",
      " 1.99176297e-02 1.34356506e-02 4.89690565e-02 7.46538565e-02\n",
      " 1.17378728e-03 3.34979314e-03 3.44769210e-02 1.94076709e-02\n",
      " 5.94344772e-02 6.71132728e-02 2.04725042e-02 1.24061736e-03\n",
      " 4.78826165e-02 6.14735112e-02 7.03133047e-02 2.27238499e-02\n",
      " 8.84296931e-03 1.34890629e-02 1.86775986e-03 1.56584382e-02\n",
      " 5.98167477e-04 1.40101207e-07 1.39737580e-07 1.45143304e-07\n",
      " 1.40780926e-07]\n",
      "0.2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(preds)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(temperature)\n\u001b[0;32m---> 18\u001b[0m next_index \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m next_char \u001b[38;5;241m=\u001b[39m chars[next_index]\n\u001b[1;32m     21\u001b[0m generated_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m next_char\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 60):\n",
    "    print(\"Epoch : \", epoch)\n",
    "    model.fit(x, y, batch_size = 128, epochs = 1)\n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index : start_index + maxlen]\n",
    "    print(\"-------------- Generated Text Seed------------------\")\n",
    "    print(generated_text)\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(f\"----------------- temperature -------------{temperature}\")\n",
    "        sys.stdout.write(generated_text)\n",
    "        for i in range(400):\n",
    "            sample = np.zeros(shape = (1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sample[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(sample, verbose = 0)[0]\n",
    "            print(preds)\n",
    "            print(temperature)\n",
    "            next_index = sample(preds, temperature = temperature)\n",
    "            next_char = chars[next_index]\n",
    "            \n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd9ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2bceb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
