{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a6492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## downloading corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420344c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 11:29:22.490388: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 11:29:22.635760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-01 11:29:22.635778: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-01 11:29:22.662136: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 11:29:23.544515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-01 11:29:23.544596: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-01 11:29:23.544605: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384b592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b6dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length :  600893\n"
     ]
    }
   ],
   "source": [
    "text = open(path).read().lower()\n",
    "print('Corpus length : ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91b9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorization of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfbe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "step = 6\n",
    "sentences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "991a41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_char.append(text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c0ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce74768",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5998814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(shape = (len(sentences), maxlen, len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecee4bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(shape = (len(next_char), len(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "040fef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for j, ch in enumerate(chars):\n",
    "        x[i, j, char_indices[ch]] = 1\n",
    "    y[i, char_indices[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d5a4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e2a5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape = (maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88f9767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 128)               95232     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 57)                7353      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4527b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = optimizers.RMSprop(learning_rate = 0.001),\n",
    "    loss = 'categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df2a4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e081ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probs = np.randoom.multinomial(1, preds, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9ed7432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:19:30.187535: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1369901520 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 66s 82ms/step - loss: 3.0372\n",
      "-------------- Generated Text Seed------------------\n",
      "attempt, it is commanded by the conscience of\n",
      "logical method\n",
      "----------------- temperature -------------0.2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sys' has no attribute 'out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temperature \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.2\u001b[39m]:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------- temperature -------------\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemperature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[38;5;241m.\u001b[39mwrite(generated_text)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m400\u001b[39m):\n\u001b[1;32m     12\u001b[0m         sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, maxlen, \u001b[38;5;28mlen\u001b[39m(chars)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sys' has no attribute 'out'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 60):\n",
    "    print(\"Epoch : \", epoch)\n",
    "    model.fit(x, y, batch_size = 128, epochs = 1)\n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index : start_index + maxlen]\n",
    "    print(\"-------------- Generated Text Seed------------------\")\n",
    "    print(generated_text)\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print(f\"----------------- temperature -------------{temperature}\")\n",
    "        sys.out.write(generated_text)\n",
    "        for i in range(400):\n",
    "            sample = np.zeros(shape = (1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sample[1, t, char_indices[char]] = 1\n",
    "            preds = model.predict(sampled, verbose = 0)[0]\n",
    "            next_index = sample(preds, temperature = temperature)\n",
    "            next_char = chars[next_index]\n",
    "            \n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd9ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
