{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "166f1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b99b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.attention = layers.MultiHeadAttention(num_heads = self.num_heads, key_dim = self.embed_dim)\n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(self.dense_dim, activation = 'relu'),\n",
    "            layers.Dense(self.embed_dim)\n",
    "        ])\n",
    "        \n",
    "        self.layernorm1 = layers.LayerNormalization()\n",
    "        self.layernorm2 = layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs, mask = None):\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = maks[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask = mask)\n",
    "        proj_input = self.layernorm1(attention_output + inputs)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm2(proj_output+ proj_input)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads\n",
    "        })\n",
    "        return config\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37fa5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embed_dim = 256\n",
    "dense_dim = 32\n",
    "num_heads = 2\n",
    "max_words = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4132c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (None, ), dtype = 'int64')\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim = embed_dim, dense_dim = dense_dim, num_heads = num_heads)(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c14bd92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_6 (Embedding)     (None, None, 256)         2560000   \n",
      "                                                                 \n",
      " transformer_encoder_5 (Tran  (None, None, 256)        543776    \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 256)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,104,033\n",
      "Trainable params: 3,104,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5b82dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1c4f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5cfe5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen = max_words)\n",
    "x_test = pad_sequences(x_test, maxlen = max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20ff1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train, np.int64)\n",
    "x_test = tf.convert_to_tensor(x_test, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4359b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.convert_to_tensor(y_train, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "198f0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:5000]\n",
    "y_val = y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1eb7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[5000:]\n",
    "y_train = y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a666f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"imdb_transformed_model.h5\",\n",
    "        metrics = 'val_acc',\n",
    "        save_best_only = True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a30b4124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 58s 360ms/step - loss: 0.1065 - acc: 0.9582 - val_loss: 1.0525 - val_acc: 0.7940\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 55s 353ms/step - loss: 0.0704 - acc: 0.9736 - val_loss: 1.0480 - val_acc: 0.7818\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 56s 359ms/step - loss: 0.0548 - acc: 0.9795 - val_loss: 1.2839 - val_acc: 0.7860\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 56s 356ms/step - loss: 0.0412 - acc: 0.9857 - val_loss: 1.5145 - val_acc: 0.7918\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 56s 359ms/step - loss: 0.0319 - acc: 0.9894 - val_loss: 1.3816 - val_acc: 0.7762\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 58s 367ms/step - loss: 0.0230 - acc: 0.9926 - val_loss: 1.6526 - val_acc: 0.7832\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 54s 347ms/step - loss: 0.0196 - acc: 0.9936 - val_loss: 1.6342 - val_acc: 0.7680\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 0.0166 - acc: 0.9941 - val_loss: 1.7095 - val_acc: 0.7824\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.0149 - acc: 0.9954 - val_loss: 1.5189 - val_acc: 0.7706\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 54s 346ms/step - loss: 0.0134 - acc: 0.9960 - val_loss: 1.8330 - val_acc: 0.7734\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 128,\n",
    "    validation_data = (x_val, y_val),\n",
    "    callbacks = callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1a425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
